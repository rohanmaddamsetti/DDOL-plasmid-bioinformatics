# DDOL-plasmid-bioinformatics by Rohan Maddamsetti, Maggie Wilson, Hye-in Son, Grayson Hamrick

Dynamic division of labor in natural communities project led by Grayson.

## Software requirements
## Python 3.10+

## COMPUTATIONAL PROTOCOL

Make a top-level directory with three directories inside, named "data", "results", and "src".  
Now copy all source code files in this repository into "src".

Now, download prokaryotes.txt into ../data/GENOME_REPORTS:  

wget https://ftp.ncbi.nlm.nih.gov/genomes/GENOME_REPORTS/prokaryotes.txt  

Then, filter the prokaryotes.txt genome data for those that have complete genomes,
and replace "GCA" with "GCF" throughout this file, so that RefSeq data and not Genbank data
is accessed in all downstream steps:  

python filter-genome-reports.py > ../results/complete-prokaryotes-with-plasmids.txt  

Then, fetch genome annotation for each row in complete-prokaryotes-with-plasmids.txt,
fetch the protein-coding genes for all chromosomes and plasmids for
each row in best-prokaryotes.txt,

These steps can be done at the same time on the Duke Compute Cluster (DCC).
And make sure these scripts are called from the src directory.
fetch-gbk-annotation runs for several hours.  

First, make some output directories.  
mkdir ../results/gbk-annotation/

Then:  
sbatch --mem=16G -t 36:00:00 --wrap="python fetch-gbk-annotation.py"  

Now run the following scripts on DCC. Some run
quite quickly, so no need to submit them to a partition on DCC--
just run them in an interactive session on DCC.  

python make-chromosome-plasmid-table.py  
python make-gbk-annotation-table.py  
python count-proteins-and-replicon-lengths.py  

Then, copy the following files from the results/  
directory onto my local machine (same directory name and file structure).  

gbk-annotation-table.csv  
chromosome-plasmid-table.csv  
replicon-lengths-and-protein-counts.csv
../results/gbk-annotation

We use the GhostKOALA algorithm associated with the KEGG database to annotate KEGG numbers:  
https://www.kegg.jp/ghostkoala/  
Then, to make input files for GhostKOALA, make a plasmid protein db as follows, and since
GhostKOALA requires a FASTA list of up to 500,000 sequences, we split the database into smaller input files.  

IMPORTANT NOTE: make-plasmid-protein-FASTA-db.py passes over genomes in which there is
a plasmid that is apparently larger than the chromosome. I found several genomes in
these complete genomes from RefSeq in which a 'plasmid' is actually the chromosome,
and the chromosome is most likely a plasmid. This is a small number of cases,
but this has a disproportionate effect on examining metabolic genes on plasmids.  

python make-plasmid-protein-FASTA-db.py  
mkdir ../results/GhostKOALA-input-files/  
python make-GhostKOALA-input-files.py  

Then, submit each of the input files in ../results/GhostKOALA-input-files/ to the
GhostKOALA webserver at https://www.kegg.jp/ghostkoala.  

Save the output files generated by GhostKOALA in ../results/GhostKOALA-output-files/,
with names like "GhostKOALA_batch10_ko_results.tsv".  

Then, run concatenate-and-filter-GhostKOALA-results.sh to generate
../results/GhostKOALA_concatenated_ko_results.tsv, and 
successful_GhostKOALA_concatenated_ko_results.tsv, which only contains rows that were
successfully mapped to a KEGG KO ID.  

Then run:  
python remove-chromosomes-from-Ghost_KOALA-results.py > ../results/filtered_successful_GhostKOALA_concatenated_ko_results.tsv
python get_unique_KEGG_IDs.py > ../results/unique_plasmid_KEGG_IDs.tsv  

to get the union of all KEGG IDs found among the plasmid genes.  

Then, upload this file to the KEGG Mapper Reconstruct webserver at:  
https://www.kegg.jp/kegg/mapper/reconstruct.html,  

and copy-paste the set of KO IDs that map to 01100 metabolic pathways into the file:  
unique_plasmid_metabolic_KEGG_IDs.txt. This file should just have KO IDs in there.  

Then, run:  
python get-plasmid-metabolic-KOs.py > ../results/plasmid_proteins_in_KEGG_metabolism.tsv  

IMPORTANT NOTE: get-plasmid-metabolic-KOs.py passes over genomes in which there is
a plasmid that is apparently larger than the chromosome. I found several genomes in
these complete genomes from RefSeq in which a 'plasmid' is actually the chromosome,
and the chromosome is most likely a plasmid. This is a small number of cases,
but this has a disproportionate effect on examining metabolic genes on plasmids.  

To generate a table of all KEGG metabolic genes in the plasmids.  

Then, to make input files for MOB-typer, do the following:  

mkdir ../results/plasmid-FASTA-references  
mkdir ../results/plasmid-MOB-typer-results  
python write-plasmid-seqs-for-MOB-typer.py  


#### Currents thoughts/ideas about the analysis.

- Use MOB-SUITE to get important plasmid data on mobility: https://github.com/phac-nml/mob-suite  

MOB-typer needs to have one DNA FASTA file per plasmid.  

- Use CLEAN deep learning network from Huimin Zhao lab to annotate EC numbers:
https://github.com/tttianhao/CLEAN  
See section: 2.4 Inference on a single FASTA file




#### Project notes from Grayson.

the goal of this project is to identify metabolic pathways distributed via HGT in natural communities, which would indicate that dynamic division of labor (DDOL) is a good move for microbes and microbial consortia harboring complex pathways. This would be compelling evidence that DDOL could be a viable engineering strategy for biomanufacturing as well. To review, our goals are as follows:
1. Curate/download a plasmid sequence database
2. Carry out initial analysis of plasmid sequences:
    a. Annotate or scan annotations of the genes present on the plasmids
    b. Check transmissibility of plasmids (using a tool like MOB-typer)
3. Map genes to KEGG nodes (this is the potentially difficult/novel step)
4. Search for patterns, such as pathways that tend to be mobilized, or other comparisons between genes on mobilized plasmids vs. non-mobilized plasmids vs. chromosomes (these patterns are the potentially novel results)

